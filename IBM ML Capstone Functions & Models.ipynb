{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80efed5-ee94-4a9b-aa5c-bc607252c899",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3413e71d-c324-4ef0-bccd-9d512e1bd80a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9343052f-d0ef-4981-b934-ec8a3722da42",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6858ba3-6657-424c-afc2-60c10d9e0e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations_for_one_user(enrolled_course_ids, unselected_course_ids, id_idx_dict, sim_matrix):\n",
    "    # Create a dictionary to store your recommendation results\n",
    "    res = {}\n",
    "    threshold = 0.6 \n",
    "\n",
    "    for enrolled_course in enrolled_course_ids:\n",
    "        for unselect_course in unselected_course_ids:\n",
    "            if enrolled_course in id_idx_dict and unselect_course in id_idx_dict:\n",
    "                # Find the indices for each enrolled_course and unselect_course based on their ids\n",
    "                enrolled_idx = id_idx_dict[enrolled_course]\n",
    "                unselect_idx = id_idx_dict[unselect_course]\n",
    "                \n",
    "                # Calculate the similarity between the enrolled_course and unselect_course\n",
    "                sim = sim_matrix[enrolled_idx][unselect_idx]\n",
    "                \n",
    "                if sim > threshold:\n",
    "                    if unselect_course not in res:\n",
    "                        res[unselect_course] = sim\n",
    "                    else:\n",
    "                        if sim >= res[unselect_course]:\n",
    "                            res[unselect_course] = sim\n",
    "                            \n",
    "    # Sort the results by similarity\n",
    "    res = {k: v for k, v in sorted(res.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7af8050-58ef-45db-b8d7-36c8bdd239f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations_for_all():\n",
    "    users = []\n",
    "    courses = []\n",
    "    sim_scores = []\n",
    "    \n",
    "    bow_df = pd.read_csv(bow_url)  \n",
    "    \n",
    "    test_users = test_users_df.groupby(['user']).max().reset_index(drop=False)\n",
    "    all_courses = set(course_df['COURSE_ID'])\n",
    "    \n",
    "    for user_id in test_users['user']:\n",
    "        enrolled_course_ids = set(test_users[test_users['user'] == user_id]['item'])\n",
    "        unselected_course_ids = all_courses.difference(enrolled_course_ids)\n",
    "        \n",
    "        # Call generate_recommendations_for_one_user for each user\n",
    "        recommendations = generate_recommendations_for_one_user(\n",
    "            enrolled_course_ids, unselected_course_ids, id_idx_dict, sim_matrix\n",
    "        )\n",
    "        \n",
    "        # Append results to lists\n",
    "        users.append(user_id)\n",
    "        courses.append(list(recommendations.keys()))\n",
    "        sim_scores.append(list(recommendations.values()))\n",
    "    \n",
    "    return users, courses, sim_scores\n",
    "\n",
    "# Example usage\n",
    "users, recommended_courses, sim_scores = generate_recommendations_for_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be09bd93-5b7f-43f3-9646-f297d14fe1f3",
   "metadata": {},
   "source": [
    "## Define & Evaluate basic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788bd83f-c1c7-4a72-a5e7-4dffa6ba7b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR CODE HERE\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create a Ridge regression model\n",
    "ridge_model = Ridge(alpha=0.2)\n",
    "\n",
    "# Fit the model on the training data\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Use cross-validation to evaluate the model\n",
    "cv_scores = cross_val_score(ridge_model, X_train, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "average_mse = -cv_scores.mean()\n",
    "print(f'Average Cross-Validated Mean Squared Error: {average_mse}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e543154-232e-425c-9090-159bc6045a23",
   "metadata": {},
   "source": [
    "## Regression with differtent hyperparameters and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b230373-9b18-4f30-a637-18be20a11657",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR CODE HERE\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming X and y are your feature matrix and target variable\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create parameter grids for hyperparameter tuning\n",
    "ridge_params = {'alpha': [0.1, 1, 10]}\n",
    "lasso_params = {'alpha': [0.1, 1, 10]}\n",
    "elasticnet_params = {'alpha': [0.1, 1, 10], 'l1_ratio': [0.1, 0.5, 0.9]}\n",
    "\n",
    "# Define scoring function (RMSE in this case)\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_model = Ridge()\n",
    "ridge_grid = GridSearchCV(ridge_model, ridge_params, scoring=scorer, cv=5)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_model = Lasso()\n",
    "lasso_grid = GridSearchCV(lasso_model, lasso_params, scoring=scorer, cv=5)\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "\n",
    "# ElasticNet Regression\n",
    "elasticnet_model = ElasticNet()\n",
    "elasticnet_grid = GridSearchCV(elasticnet_model, elasticnet_params, scoring=scorer, cv=5)\n",
    "elasticnet_grid.fit(X_train, y_train)\n",
    "\n",
    "# Print best hyperparameters and corresponding RMSE for each model\n",
    "print(\"Ridge Best Hyperparameters: \", ridge_grid.best_params_)\n",
    "print(\"Ridge RMSE on Test Set: \", np.sqrt(mean_squared_error(y_test, ridge_grid.predict(X_test))))\n",
    "\n",
    "print(\"Lasso Best Hyperparameters: \", lasso_grid.best_params_)\n",
    "print(\"Lasso RMSE on Test Set: \", np.sqrt(mean_squared_error(y_test, lasso_grid.predict(X_test))))\n",
    "\n",
    "print(\"ElasticNet Best Hyperparameters: \", elasticnet_grid.best_params_)\n",
    "print(\"ElasticNet RMSE on Test Set: \", np.sqrt(mean_squared_error(y_test, elasticnet_grid.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3ed2dd-9f07-476a-b12d-4124e947c2da",
   "metadata": {},
   "source": [
    "## Define & Evaluate Classification Models\n",
    "### Note: Accuracy metrics switced for RMSE, however, labels remain \"Accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab5689d-ba76-49eb-8429-fa6f0c37c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=rs)\n",
    "\n",
    "# Logistic Regression\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train, y_train)\n",
    "logreg_predictions = logreg_model.predict(X_test)\n",
    "logreg_accuracy = sqrt(mean_squared_error(y_test, logreg_predictions))\n",
    "print(\"Logistic Regression Accuracy: \", logreg_accuracy)\n",
    "\n",
    "# Decision Tree\n",
    "tree_model = DecisionTreeClassifier(max_depth=5, random_state=rs)\n",
    "tree_model.fit(X_train, y_train)\n",
    "tree_predictions = tree_model.predict(X_test)\n",
    "tree_accuracy = sqrt(mean_squared_error(y_test, tree_predictions))\n",
    "print(\"Decision Tree Accuracy: \", tree_accuracy)\n",
    "\n",
    "# Support Vector Machine (SVM)\n",
    "svm_model = SVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "svm_accuracy = sqrt(mean_squared_error(y_test, svm_predictions))\n",
    "print(\"SVM Accuracy: \", svm_accuracy)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier(max_depth=5, random_state=rs)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "rf_accuracy = sqrt(mean_squared_error(y_test, rf_predictions))\n",
    "print(\"Random Forest Accuracy: \", rf_accuracy)\n",
    "\n",
    "# Bagging\n",
    "bagging_model = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=rs)\n",
    "bagging_model.fit(X_train, y_train)\n",
    "bagging_predictions = bagging_model.predict(X_test)\n",
    "bagging_accuracy = sqrt(mean_squared_error(y_test, bagging_predictions))\n",
    "print(\"Bagging Accuracy: \", bagging_accuracy)\n",
    "\n",
    "# Boosting (AdaBoost)\n",
    "adaboost_model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=50, random_state=rs)\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "adaboost_predictions = adaboost_model.predict(X_test)\n",
    "adaboost_accuracy = sqrt(mean_squared_error(y_test, adaboost_predictions))\n",
    "print(\"AdaBoost Accuracy: \", adaboost_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cefe6a-829b-4b04-981a-fd7ba0262e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "### WRITE YOUR CODE HERE\n",
    "\n",
    "### The main evaluation metrics could be accuracy, recall, precision, F score, and AUC.\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
    "\n",
    "# Assuming X and y are your feature matrix and target variable\n",
    "# Assuming models are already trained (e.g., logreg_model, tree_model, svm_model, etc.)\n",
    "\n",
    "models = [logreg_model, tree_model, svm_model, rf_model, bagging_model, adaboost_model]\n",
    "\n",
    "for model in models:\n",
    "    # Get predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Accuracy for {type(model).__name__}: {accuracy:.4f}\")\n",
    "    \n",
    "    # Precision, Recall, F1 Score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, predictions, average='binary')\n",
    "    print(f\"Precision for {type(model).__name__}: {precision:.4f}\")\n",
    "    print(f\"Recall for {type(model).__name__}: {recall:.4f}\")\n",
    "    print(f\"F1 Score for {type(model).__name__}: {f1:.4f}\")\n",
    "    \n",
    "    # AUC Score\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    print(f\"AUC for {type(model).__name__}: {auc:.4f}\")\n",
    "\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cee410b-4e3a-40fe-ae83-92ecb86fa79e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create & evaluate using KNN (Use numpy, pandas, and sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1cc36-65d1-47d8-9563-00c7ec4858a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.DataFrame(rating_df.pivot(index='user', columns='item', values='rating').fillna(0).reset_index().rename_axis(index=None, columns=None))\n",
    "\n",
    "# Extract the rating columns (all columns except 'user')\n",
    "rating_columns = ratings.columns[1:]  # Assuming the first column is 'user'\n",
    "\n",
    "# Get the user IDs from the original DataFrame\n",
    "user_ids = ratings['user']\n",
    "\n",
    "# Create a user-item matrix (users as rows, ratings as columns)\n",
    "user_item_matrix = ratings[rating_columns].values\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "train_matrix, test_matrix, train_user_ids, test_user_ids = train_test_split(user_item_matrix, user_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# Calculate the cosine similarity between users on the training set\n",
    "user_similarity_matrix = cosine_similarity(train_matrix)\n",
    "\n",
    "# Convert the similarity matrix to a DataFrame for better readability\n",
    "user_similarity_df = pd.DataFrame(user_similarity_matrix, index=train_user_ids, columns=train_user_ids)\n",
    "\n",
    "\n",
    "## - For each user, find its k nearest neighbors in the sim matrix\n",
    "# Define the number of nearest neighbors (k)\n",
    "def find_k_nearest_neighbors2(user_similarity_matrix, user_id, k):\n",
    "    if user_id in user_similarity_matrix.index:\n",
    "        user_similarities = user_similarity_matrix.loc[user_id]\n",
    "        most_similar_users = user_similarities.sort_values(ascending=False)\n",
    "        # Exclude the user itself from the most similar users\n",
    "        most_similar_users = most_similar_users.drop(user_id)\n",
    "        nearest_neighbors = most_similar_users.head(k)\n",
    "    else:\n",
    "        # Handle the case where the user ID is not found in the similarity matrix\n",
    "        nearest_neighbors = pd.Series(dtype=float)  # An empty Series\n",
    "    return nearest_neighbors\n",
    "\n",
    "# Define the estimated ratings list\n",
    "estimated_ratings = []\n",
    "\n",
    "# Loop through each user-item pair in the test dataset\n",
    "for user_id, item_id, actual_rating in testset:\n",
    "    # Find the k nearest neighbors for the user\n",
    "    user_neighbors = find_k_nearest_neighbors2(user_similarity_matrix_df, user_id, k)\n",
    "    if len(user_neighbors) == 0:\n",
    "        # Handle the case where there are no neighbors for the user\n",
    "        estimated_rating = 0  # You can adjust this value\n",
    "    else:\n",
    "        # Initialize variables for the numerator and denominator\n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "        # Loop through the nearest neighbors\n",
    "        for neighbor_id, similarity in enumerate(user_neighbors):\n",
    "            # Check if the neighbor has rated the item\n",
    "            if item_id in user_item_matrix.columns:\n",
    "                neighbor_rating = user_item_matrix[neighbor_id, item_id]\n",
    "                # Accumulate the numerator and denominator\n",
    "                numerator += similarity * neighbor_rating\n",
    "                denominator += similarity\n",
    "        # Calculate the estimated rating using the formula\n",
    "        if denominator != 0:\n",
    "            estimated_rating = numerator / denominator\n",
    "        else:\n",
    "            # Handle the case where there are no neighbors who have rated the item\n",
    "            estimated_rating = 0  # You can adjust this value\n",
    "\n",
    "    # Append the estimated rating to the list\n",
    "    estimated_ratings.append((user_id, item_id, actual_rating, estimated_rating))\n",
    "\n",
    "# Convert the estimated ratings list to a Pandas DataFrame for further analysis\n",
    "estimated_ratings_df = pd.DataFrame(estimated_ratings, columns=['User', 'Item', 'Actual_Rating', 'Estimated_Rating'])\n",
    "    \n",
    "#evaluate with RMSE\n",
    "# Calculate the squared errors and accumulate them\n",
    "squared_errors = [(actual_rating - estimated_rating) ** 2 for actual_rating, estimated_rating in zip(estimated_ratings_df['Actual_Rating'], estimated_ratings_df['Estimated_Rating'])]\n",
    "\n",
    "# Calculate the mean of squared errors\n",
    "mean_squared_error = np.mean(squared_errors)\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmse = math.sqrt(mean_squared_error)\n",
    "\n",
    "# The 'rmse' variable now contains the RMSE value\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b702d515-258a-4575-84e5-fe4893139aea",
   "metadata": {},
   "source": [
    "## Implement Customized ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac30f4d5-0712-48bd-902b-1b6da209401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Update RecommenderNet() class\n",
    "class ImprovedRecommenderNet(keras.Model):\n",
    "    \n",
    "    def __init__(self, num_users, num_items, embedding_size=32, num_hidden_units=64, activation='relu', **kwargs):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        :param int num_users: number of users\n",
    "        :param int num_items: number of items\n",
    "        :param int embedding_size: the size of embedding vector\n",
    "        :param int num_hidden_units: the number of units in hidden layers\n",
    "        :param str activation: activation function for hidden layers\n",
    "        \"\"\"\n",
    "        super(ImprovedRecommenderNet, self).__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_hidden_units = num_hidden_units\n",
    "        self.activation = activation\n",
    "        \n",
    "        # Define user and item embedding layers\n",
    "        self.user_embedding_layer = layers.Embedding(\n",
    "            input_dim=num_users,\n",
    "            output_dim=embedding_size,\n",
    "            name='user_embedding_layer',\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.item_embedding_layer = layers.Embedding(\n",
    "            input_dim=num_items,\n",
    "            output_dim=embedding_size,\n",
    "            name='item_embedding_layer',\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        \n",
    "        # Define user and item bias layers\n",
    "        self.user_bias = layers.Embedding(\n",
    "            input_dim=num_users,\n",
    "            output_dim=1,\n",
    "            name=\"user_bias\")\n",
    "        self.item_bias = layers.Embedding(\n",
    "            input_dim=num_items,\n",
    "            output_dim=1,\n",
    "            name=\"item_bias\")\n",
    "        \n",
    "        # Additional hidden layers\n",
    "        self.hidden_layers = [layers.Dense(num_hidden_units, activation=activation) for _ in range(2)]\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = layers.Dense(1, activation='sigmoid')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding_layer(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        item_vector = self.item_embedding_layer(inputs[:, 1])\n",
    "        item_bias = self.item_bias(inputs[:, 1])\n",
    "        \n",
    "        # Calculate the dot product\n",
    "        dot_user_item = tf.tensordot(user_vector, item_vector, 2)\n",
    "        \n",
    "        # Add user and item biases\n",
    "        x = dot_user_item + user_bias + item_bias\n",
    "        \n",
    "        # Pass through hidden layers\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # Final output layer\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x\n",
    "## compile and fit the updated model\n",
    "embedding_size = 32\n",
    "model2 = RecommenderNet(num_users, num_items, embedding_size)\n",
    "\n",
    "model2.compile(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    optimizer=keras.optimizers.Adam(),          \n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "history2 = model2.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=64, verbose=1)\n",
    "\n",
    "model2.save(\"ann_model2\", save_format=\"tf\")\n",
    "\n",
    "# Access validation loss from the history object\n",
    "val_loss = history2.history['val_loss']\n",
    "\n",
    "# Plot the validation loss\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
